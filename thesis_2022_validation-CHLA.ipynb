{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33181bba-19e3-4763-83c5-de24dfd368d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.uk import UniversalKriging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import random\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca25b81-c688-4ca2-9cd5-5a3e29e9982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_land_mask import globe\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ac3103-df12-438e-835d-8b2d4c53915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('C:/Users/Acer/Documents/SchoolHard/Thesis/Code/dataset//chl_merged_2002_08_2022_10.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cb730-b0ff-4971-a3bf-6ee331df6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753e5396-e1b2-4adc-a198-bc248e34c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path\n",
    "dir_path = \"C:/Users/Acer/Documents/SchoolHard/Thesis/Code/fin_csv/UniKrig\"\n",
    "\n",
    "# Get all file names inside the directory\n",
    "file_names = os.listdir(dir_path)\n",
    "\n",
    "# Concatenate the file names with the directory path\n",
    "file_paths = [os.path.join(dir_path, file_name) for file_name in file_names]\n",
    "\n",
    "#dummy_df = pd.read_csv(file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4981008d-5c0a-479c-9388-040180b34b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define time steps, 243 monthly observations\n",
    "start_date = pd.Timestamp('2002-08-01')\n",
    "end_date = pd.Timestamp('2022-10-01')\n",
    "\n",
    "#Create a new time coordinate that represents the month and year\n",
    "time_coords = pd.date_range(start=start_date, end=end_date, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616ff04e-e9bd-48c4-9cce-32734e2c287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#2022 months\n",
    "time_coords_2022 = time_coords[time_coords.year == 2022]\n",
    "\n",
    "# Extract the month from each timestamp\n",
    "months_2022 = time_coords_2022.month\n",
    "\n",
    "# Print the resulting integer for each month in 2022\n",
    "for month in months_2022:\n",
    "    print(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5690b66-f933-4854-a0d4-0782a240d16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01',\n",
       "               '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01',\n",
       "               '2022-09-01', '2022-10-01'],\n",
       "              dtype='datetime64[ns]', freq='MS')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_coords_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa286e6b-03c2-4167-a3a7-154abeae107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(time_coords_2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5dd7e59-d886-422f-9db0-8ae064bf6586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month 0: 0.002543025957762424\n",
      "Month 0: 0.05042842410548266\n",
      "Month 0: 0.02386449417234882\n",
      "Month 1: 0.00833610111495924\n",
      "Month 1: 0.09130225142327675\n",
      "Month 1: 0.05558620563343114\n",
      "Month 2: 0.03346056785186741\n",
      "Month 2: 0.1829223000398459\n",
      "Month 2: 0.10290793002984833\n",
      "Month 3: 0.004630139582910748\n",
      "Month 3: 0.06804512901678376\n",
      "Month 3: 0.03799233261945022\n",
      "Month 4: 0.041124415123277545\n",
      "Month 4: 0.20279155584806174\n",
      "Month 4: 0.09974258560545905\n",
      "Month 5: 0.02271953442665323\n",
      "Month 5: 0.15073000506419826\n",
      "Month 5: 0.07037802029394498\n",
      "Month 6: 0.04232827271257395\n",
      "Month 6: 0.2057383598470979\n",
      "Month 6: 0.12333195709379786\n",
      "Month 7: 0.09504169107432944\n",
      "Month 7: 0.30828832458322103\n",
      "Month 7: 0.14395486343623234\n",
      "Month 8: 0.005300298806320167\n",
      "Month 8: 0.07280315107411332\n",
      "Month 8: 0.04419601437266832\n",
      "Month 9: 0.00957527349871384\n",
      "Month 9: 0.09785332645706961\n",
      "Month 9: 0.05854489020216362\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(time_coords_2022)):\n",
    "    \n",
    "    mean_data = pd.read_csv(file_paths[i])\n",
    "    \n",
    "    month_sst = ds['chlor_a'].sel(time= time_coords_2022[i])\n",
    "    \n",
    "    lon = ds['lon'].values\n",
    "    lat = ds['lat'].values\n",
    "    \n",
    "    #Convert the dataset to a pandas dataframe\n",
    "    df = month_sst.to_dataframe().reset_index()\n",
    "    \n",
    "    #convert dataframe to geodataframe \n",
    "    gdf = gpd.GeoDataFrame(\n",
    "    df, \n",
    "    geometry=gpd.points_from_xy(df.lon, df.lat)\n",
    "    )\n",
    "    \n",
    "    # Set the CRS of the geodataframe\n",
    "    gdf.crs = 'WGS84'\n",
    "    \n",
    "    #dropna in gdf\n",
    "    gdf = gdf.dropna()\n",
    "    \n",
    "    #winzorization\n",
    "    #winzorize month_gdf before interpolation\n",
    "    # Calculate winsorized values\n",
    "    winsorized = np.clip(gdf['chlor_a'], gdf['chlor_a'].quantile(0.05), gdf['chlor_a'].quantile(0.95))\n",
    "\n",
    "    # Define Huber loss function\n",
    "    def huber_loss(residuals, c=1.345):\n",
    "        return np.where(abs(residuals) < c, 0.5 * residuals ** 2, c * (abs(residuals) - 0.5 * c))\n",
    "\n",
    "    # Define M-estimator function\n",
    "    def m_estimator(data, loss_function, tuning_param):\n",
    "        # Add a constant column to serve as the intercept\n",
    "        exog = sm.add_constant(data)\n",
    "        model = sm.RLM(gdf['chlor_a'], exog=exog, M=sm.robust.norms.HuberT(t=tuning_param))\n",
    "        results = model.fit()\n",
    "        return results.fittedvalues\n",
    "\n",
    "    # Apply M-estimator function to winsorized data\n",
    "    final_values = m_estimator(winsorized, huber_loss, 1.345)\n",
    "\n",
    "    # Add final values as a new column to your original GeoDataFrame\n",
    "    gdf['chlor_a'] = final_values\n",
    "\n",
    "    # Convert the 'final_values' column to float data type if necessary\n",
    "    gdf['chlor_a'] = gdf['chlor_a'].astype(float)\n",
    "    \n",
    "    # Extract X, Y, and Z values\n",
    "    x = gdf.geometry.x\n",
    "    y = gdf.geometry.y\n",
    "    z = gdf['chlor_a']\n",
    "    \n",
    "    #Universal Kriging\n",
    "    unkrig = UniversalKriging(x, y, z, variogram_model=\"linear\", verbose=False, enable_plotting=False)\n",
    "    \n",
    "    x_grid = np.linspace(lon.min(), lon.max(), num=400)\n",
    "    y_grid = np.linspace(lat.min(), lat.max(), num=400)\n",
    "    XI, YI = np.meshgrid(x_grid, y_grid)\n",
    "    \n",
    "    z_interp, sigma = unkrig.execute(\"grid\", x_grid, y_grid)\n",
    "    \n",
    "    # Create new GeoDataFrame with interpolated values\n",
    "    interp_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(XI.ravel(), YI.ravel()))\n",
    "    interp_gdf['estimated_chla'] = z_interp.ravel()\n",
    "\n",
    "    # add lat and lon columns\n",
    "    interp_gdf['lat'] = interp_gdf['geometry'].apply(lambda p: p.y)\n",
    "    interp_gdf['lon'] = interp_gdf['geometry'].apply(lambda p: p.x)\n",
    "\n",
    "    estimated_chla = interp_gdf.pop('estimated_chla')\n",
    "    interp_gdf['estimated_chla'] = estimated_chla\n",
    "\n",
    "    idf = pd.DataFrame(interp_gdf.drop('geometry', axis=1))\n",
    "\n",
    "    #mask land area on dataframe version of interpolated results\n",
    "    mask = globe.is_land(idf['lat'], idf['lon'])\n",
    "    final_idf = idf[~mask]\n",
    "\n",
    "    #mask land area on geodataframe of interpolated results\n",
    "    mask = globe.is_land(interp_gdf['lat'], interp_gdf['lon'])\n",
    "    interp_gdf = interp_gdf[~mask]\n",
    "\n",
    "    interp_gdf = interp_gdf.reset_index()\n",
    "    \n",
    "    mse = mean_squared_error(interp_gdf['estimated_chla'], mean_data['mean_chla'])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(interp_gdf['estimated_chla'], mean_data['mean_chla'])\n",
    "\n",
    "    print(\"Month \" + str(i) + \": \" + str(mse))\n",
    "    print(\"Month \" + str(i) + \": \" + str(rmse))\n",
    "    print(\"Month \" + str(i) + \": \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00794db1-96af-4adc-ac56-ed4e2142c389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
